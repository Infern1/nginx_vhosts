# force redirect www to non-www
server {
	listen 80;
	server_name www.@@HOSTNAME@@;
	return 301 $scheme://@@HOSTNAME@@$request_uri;
}

# server setup
server {
  server_name @@HOSTNAME@@;
  root "@@PATH@@";

  index index.php;
  client_max_body_size 10m;

	access_log @@LOG_PATH@@/access.log;
	error_log @@LOG_PATH@@/error.log;
	
	if ($http_user_agent ~* (Baiduspider|webalta|nikto|wkito|pikto|scan|acunetix|morfeus|webcollage|youdao) ) {
       return 401;
    }

    if ($http_user_agent ~* (HTTrack|clshttp|archiver|loader|email|harvest|extract|grab|miner) ) {
       return 401;
    }

	location / {
        # if you're just using wordpress and don't want extra rewrites
        # then replace the word @rewrites with /index.php
        try_files $uri $uri/ @rewrites;
	}
	
    location @rewrites {
        # Can put some of your own rewrite rules in here
        # for example rewrite ^/~(.*)/(.*)/? /users/$1/$2 last;
        # If nothing matches we'll just send it to /index.php
        rewrite ^ /index.php last;
    }
    
    #location ~ \.php {
	location ~ "^(.+\.php)($|/)" {
        try_files $uri /index.php; 
        include fastcgi_params;

        fastcgi_split_path_info ^(.+\.php)(/.+)$;
        fastcgi_param  PATH_INFO          $fastcgi_path_info;
        #fastcgi_param  PATH_TRANSLATED    $document_root$fastcgi_path_info;

        fastcgi_pass   unix:@@SOCKET@@;

    }


	location ~* \.(js|css|png|jpg|jpeg|gif|ico)$ {
			expires max;
			log_not_found off;
			access_log off;
	}
	
    # This block will catch static file requests, such as images, css, js
    # The ?: prefix is a 'non-capturing' mark, meaning we do not require
    # the pattern to be captured into $1 which should help improve performance
    location ~* \.(?:ico|css|js|gif|jpe?g|png)$ {
        # Some basic cache-control for static files to be sent to the browser
        expires max;
        add_header Pragma public;
        add_header Cache-Control "public, must-revalidate, proxy-revalidate";
	}
 
    # remove the robots line if you want to use wordpress' virtual robots.txt
    location = /robots.txt  { access_log off; log_not_found off; }
    location = /favicon.ico { access_log off; log_not_found off; }  
 
    # this prevents hidden files (beginning with a period) from being served
    location ~ /\.          { access_log off; log_not_found off; deny all; }
 
	location ~* /\.(ht|git|svn) {
		deny  all;
	}
}
